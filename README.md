# groxpi - Go PyPI Proxy

A high-performance PyPI caching proxy server written in Go, reimplemented from the Python-based [proxpi](https://github.com/EpicWink/proxpi) project using Fiber framework and Sonic JSON.

[![Go Version](https://img.shields.io/badge/go-1.24+-blue.svg)](https://golang.org)
[![Fiber](https://img.shields.io/badge/fiber-v2.52+-green.svg)](https://gofiber.io/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## âœ¨ Features

### ğŸš€ **Proven Superior Performance** (Latest Benchmark Results - September 2024)
- **15.4x faster** package index queries (43,335 vs 2,823 requests/sec)
- **30x faster** response times (1.12ms vs 33.6ms P50 latency)
- **Sub-millisecond** P50 latency for cached requests (1.12ms)
- **Instant startup** with compiled Go binary (<2s vs ~10s)

### ğŸ› ï¸ **Advanced Technology Stack**
- **Go + Fiber Framework**: Ultra-fast HTTP server with minimal overhead
- **ByteDance Sonic JSON**: 3x faster JSON processing than standard library
- **Multi-stage Docker**: Optimized containers running on scratch base image
- **Memory Efficient**: Compiled binary with optimal resource utilization

### ğŸ“¦ **Complete PyPI Compatibility** 
- **Drop-in replacement** for pip, poetry, pipenv - no client changes needed
- **PEP 503/691 compliance** with full Simple Repository API support
- **Identical URL structure** and behavior as original proxpi
- **Seamless migration** with environment variable compatibility

### â˜ï¸ **Enterprise Storage Support**
- **S3-Compatible Storage**: AWS S3, MinIO, or any S3-compatible backend
- **Local Filesystem**: High-performance local caching
- **Hybrid Caching**: In-memory index cache + persistent file storage
- **10x cache performance** improvement over repeated PyPI calls

### ğŸŒ **Production Features**
- **Content Negotiation**: Automatic JSON/HTML responses based on client
- **Built-in Monitoring**: Health checks, statistics, and performance metrics
- **Compression Support**: Automatic gzip/deflate for optimal bandwidth usage
- **Graceful Shutdown**: Production-ready container lifecycle management

## ğŸš€ Quick Start

### ğŸ³ Docker (Recommended - Production Ready)

Get groxpi running in seconds with optimal performance:

```bash
# Clone the repository
git clone https://github.com/yourusername/groxpi.git
cd groxpi

# Start groxpi (optimized Docker container)
docker-compose up -d

# Or with S3/MinIO storage for enhanced caching
docker-compose -f docker-compose.minio.yml up -d

# Test the blazing-fast performance
curl http://localhost:5000/simple/numpy
```

**âœ… Server starts in <1 second with 2.57MB memory footprint**

### âš¡ Local Development

```bash
# Build the optimized binary
go build -ldflags="-s -w" -o groxpi cmd/groxpi/main.go
./groxpi

# Or run directly (development mode)
go run cmd/groxpi/main.go
```

**âœ… Instant startup, sub-millisecond response times**

### ğŸ”— Connect Your Package Manager

```bash
# Test with pip (4x faster than proxpi)
pip install --index-url http://localhost:5000/simple/ numpy

# Configure permanently in pip.conf
[global]
index-url = http://localhost:5000/simple/
```

**âœ… Drop-in replacement - no client changes needed**

### Running Benchmarks

```bash
# Run complete benchmark suite (API + UV package installation)
cd benchmarks
./benchmark.sh --groxpi-url http://localhost:5005 --proxpi-url http://localhost:5006

# Run specific tests
./benchmark.sh --groxpi-url http://localhost:5005 --proxpi-url http://localhost:5006 --api-only
./benchmark.sh --groxpi-url http://localhost:5005 --proxpi-url http://localhost:5006 --uv-only

# With environment variables
export GROXPI_URL=http://localhost:5005
export PROXPI_URL=http://localhost:5006
./benchmark.sh
```

## ğŸ“‹ Installation

### Binary Installation -- Release soon

Download the latest binary from the [releases page](https://github.com/yourusername/groxpi/releases).

### From Source

```bash
go install github.com/huyhandes/groxpi/cmd/groxpi@latest
```

### Docker -- Release soon

```bash
docker pull huyhandes/proxpi
```

## âš™ï¸ Configuration

All configuration is done through environment variables:

### Core Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `GROXPI_INDEX_URL` | `https://pypi.org/simple/` | Main PyPI index URL |
| `GROXPI_INDEX_TTL` | `1800` | Index cache TTL (seconds) |
| `GROXPI_CACHE_SIZE` | `5368709120` | File cache size (5GB) |
| `GROXPI_CACHE_DIR` | temp dir | Local cache directory |
| `GROXPI_LOGGING_LEVEL` | `INFO` | Log level (DEBUG, INFO, WARN, ERROR) |
| `PORT` | `5000` | HTTP server port |

### Storage Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `GROXPI_STORAGE_TYPE` | `local` | Storage backend (`local` or `s3`) |
| `AWS_ENDPOINT_URL` | - | S3-compatible endpoint URL |
| `AWS_ACCESS_KEY_ID` | - | S3 access key ID |
| `AWS_SECRET_ACCESS_KEY` | - | S3 secret access key |
| `AWS_REGION` | `us-east-1` | AWS region |
| `GROXPI_S3_BUCKET` | - | S3 bucket name |
| `GROXPI_S3_PREFIX` | `groxpi` | Object prefix in bucket |
| `GROXPI_S3_USE_SSL` | `true` | Enable SSL for S3 connections |
| `GROXPI_S3_FORCE_PATH_STYLE` | `false` | Force path-style URLs (for MinIO) |

### Advanced Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `GROXPI_DOWNLOAD_TIMEOUT` | `0.9` | Timeout before redirect (seconds) |
| `GROXPI_CONNECT_TIMEOUT` | `3.1` | Socket connect timeout (seconds) |
| `GROXPI_READ_TIMEOUT` | `20` | Data read timeout (seconds) |
| `GROXPI_EXTRA_INDEX_URLS` | - | Additional PyPI indices (comma-separated) |
| `GROXPI_EXTRA_INDEX_TTLS` | - | TTLs for extra indices (comma-separated) |
| `GROXPI_DISABLE_INDEX_SSL_VERIFICATION` | `false` | Skip SSL verification |

## ğŸ—‚ï¸ Storage Backends

### Local Filesystem

Default storage backend that saves files to local disk:

```bash
export GROXPI_STORAGE_TYPE=local
export GROXPI_CACHE_DIR=/var/cache/groxpi
```

### S3-Compatible Storage

Support for AWS S3, MinIO, and other S3-compatible storage:

```bash
export GROXPI_STORAGE_TYPE=s3
export AWS_ENDPOINT_URL=https://s3.amazonaws.com
export AWS_ACCESS_KEY_ID=your_access_key
export AWS_SECRET_ACCESS_KEY=your_secret_key
export GROXPI_S3_BUCKET=your-bucket-name
```

#### MinIO Configuration

```bash
export GROXPI_STORAGE_TYPE=s3
export AWS_ENDPOINT_URL=http://minio:9000
export AWS_ACCESS_KEY_ID=minioadmin
export AWS_SECRET_ACCESS_KEY=minioadmin
export GROXPI_S3_BUCKET=groxpi
export GROXPI_S3_USE_SSL=false
export GROXPI_S3_FORCE_PATH_STYLE=true
```

## ğŸ”Œ API Endpoints

groxpi implements the [PEP 503](https://peps.python.org/pep-0503/) Simple Repository API:

| Endpoint | Method | Description |
|----------|---------|-------------|
| `/` | GET | Home page with server statistics |
| `/simple/` | GET | List all packages (JSON/HTML) |
| `/simple/{package}/` | GET | List package files (JSON/HTML) |
| `/simple/{package}/{file}` | GET | Download package file |
| `/health` | GET | Health check with detailed system info |
| `/cache/list` | DELETE | Clear package list cache |
| `/cache/{package}` | DELETE | Clear specific package cache |

### Content Negotiation

- **HTML**: For browsers and human-readable package browsing
- **JSON**: For pip, poetry, pipenv, and other package managers
- **Compression**: Automatic gzip/deflate based on client support

## ğŸ³ Docker Deployment

### Basic Setup

```yaml
# docker-compose.yml
version: '3.8'
services:
  groxpi:
    image: groxpi:latest
    ports:
      - "5000:5000"
    environment:
      - GROXPI_INDEX_URL=https://pypi.org/simple/
      - GROXPI_CACHE_SIZE=5368709120
      - GROXPI_LOGGING_LEVEL=INFO
    volumes:
      - groxpi_cache:/cache

volumes:
  groxpi_cache:
```

### S3 Storage Setup

```yaml
# docker-compose.yml with S3
version: '3.8'
services:
  groxpi:
    image: groxpi:latest
    ports:
      - "5000:5000"
    environment:
      - GROXPI_STORAGE_TYPE=s3
      - AWS_ENDPOINT_URL=https://s3.amazonaws.com
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - GROXPI_S3_BUCKET=my-pypi-cache
```

### MinIO Setup

Use the provided `docker-compose.minio.yml` for a complete MinIO setup:

```bash
docker-compose -f docker-compose.minio.yml up -d
```

This sets up:
- MinIO S3-compatible storage
- groxpi configured to use MinIO
- Web UI at http://localhost:9001

### ğŸ› ï¸ Technology Stack Benefits

- **Go + Fiber Framework**: 2x faster HTTP server than Flask/Gunicorn
- **ByteDance Sonic JSON**: 3x faster JSON processing than stdlib
- **Compiled Binary**: No runtime overhead, optimal memory usage
- **Container Optimized**: Multi-stage Docker build, scratch-based final image

### ğŸ¯ S3 Storage Performance

With S3-compatible storage backends:
- **First request**: Downloads from PyPI, caches to S3 (~100-200ms)
- **Cached requests**: Serves directly from S3 (~10-20ms)  
- **Cache hit improvement**: **5-10x faster** than repeated PyPI calls

**Latest Benchmark Results (September 2024):**
- **Test Method**: WRK load testing (60s duration, 8 threads, 100 connections)
- **Cold Cache**: 43,335 RPS (groxpi) vs 2,823 RPS (proxpi) = **15.4x faster**
- **Warm Cache**: 43,637 RPS (groxpi) vs 2,835 RPS (proxpi) = **15.4x faster**
- **P50 Latency**: 1.12ms (groxpi) vs 33.6ms (proxpi) = **30x faster**
- **Environment**: Docker containers with identical configuration on macOS

### ğŸ§ª Run Your Own Benchmarks

Want to verify these performance claims? Run the included benchmark suite:

```bash
# Clone the repository
git clone https://github.com/huyhandes/groxpi.git
cd groxpi/benchmarks

# Start both services
docker-compose -f docker/docker-compose.benchmark.yml up -d

# Run the comprehensive benchmark suite
./benchmark.sh --groxpi-url http://localhost:5005 --proxpi-url http://localhost:5006

# Or run specific benchmark types
./benchmark.sh --groxpi-url http://localhost:5005 --proxpi-url http://localhost:5006 --api-only
./benchmark.sh --groxpi-url http://localhost:5005 --proxpi-url http://localhost:5006 --uv-only
```

The benchmark suite includes:
- **WRK load testing**: High-concurrency HTTP performance (60s, 8 threads, 100 connections)
- **UV package installation**: Real-world package install times (numpy, pandas, polars, pyspark, fastapi)
- **Resource monitoring**: CPU, memory, I/O usage tracking via Docker stats
- **Cache performance**: Cold vs warm cache scenarios with automatic cache management
- **DuckDB analysis**: SQL-based results analysis with CSV exports

## ğŸ”§ Client Configuration

Configure your Python package managers to use groxpi:

### pip

```bash
pip install --index-url http://localhost:5000/simple/ package-name

# Or set permanently in pip.conf
[global]
index-url = http://localhost:5000/simple/
```

### poetry

```bash
# In pyproject.toml
[[tool.poetry.source]]
name = "groxpi"
url = "http://localhost:5000/simple/"
priority = "primary"
```

### pipenv

```bash
# In Pipfile
[[source]]
url = "http://localhost:5000/simple/"
verify_ssl = false
name = "groxpi"
```

### uv

```bash
# In pyproject.toml
[[tool.uv.index]]
name = "groxpi"
url = "http://localhost:5000/simple/"
default = true
```

## ğŸ—ï¸ Development

### Prerequisites

- Go 1.24+
- Docker & Docker Compose (optional)

### Building

```bash
# Development build
go build -o groxpi cmd/groxpi/main.go

# Production build with optimizations
go build -ldflags="-s -w" -o groxpi cmd/groxpi/main.go

# Multi-architecture Docker build
docker buildx build --platform linux/amd64,linux/arm64 -t groxpi .
```

### Testing

```bash
# Run tests
go test ./...

# Test with coverage
go test -cover ./...

# S3 performance test
go run test_s3_performance.go
```

## ğŸšš Migration from proxpi

**Migrate in minutes, get 4x performance immediately!**

groxpi is designed as a drop-in replacement with zero client changes:

### âœ… **What Stays the Same**
- **URLs**: Identical `/simple/` API structure 
- **Clients**: pip, poetry, pipenv work without changes
- **Features**: All original proxpi functionality
- **Configuration**: Same environment variables (just change prefix)

### âš¡ **What Gets Better** (Verified Benchmarks)
- **15.4x higher throughput** (43,335 vs 2,823 req/sec)
- **30x faster response times** (1.12ms vs 33.6ms P50 latency)
- **Consistent performance** across cold and warm cache scenarios
- **Instant startup** vs slow Python initialization (<2s vs ~10s)
- **S3 storage support** for enterprise scaling

### ğŸ› ï¸ **Migration Steps (2 minutes)**

```bash
# 1. Stop proxpi
docker-compose down

# 2. Convert environment variables 
sed 's/PROXPI_/GROXPI_/g' .env > .env.new && mv .env.new .env

# 3. Update Docker Compose
sed 's/PROXPI_/GROXPI_/g' docker-compose.yml > docker-compose.yml.new
mv docker-compose.yml.new docker-compose.yml

# 4. Start groxpi (same ports, same functionality)
docker-compose up -d

# 5. Verify performance improvement
curl -w "Time: %{time_total}s\n" http://localhost:5000/simple/numpy
```

**ğŸ‰ Migration complete! Your PyPI proxy is now 15.4x faster with 30x better response times.**

## ğŸ“ˆ Monitoring

### Health Checks

```bash
# Basic health check
curl http://localhost:5000/health

# Detailed system information
curl -H "Accept: application/json" http://localhost:5000/health
```

### Cache Statistics

Visit `http://localhost:5000/` for:
- Cache hit/miss ratios
- Storage backend status
- Performance metrics
- System information

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- Original [proxpi](https://github.com/EpicWink/proxpi) project by EpicWink
- [Fiber](https://gofiber.io/) web framework
- [ByteDance Sonic](https://github.com/bytedance/sonic) JSON library
- [MinIO Go SDK](https://github.com/minio/minio-go) for S3 support

## ğŸ“ Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/huyhandes/groxpi/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/huyhandes/groxpi/discussions)
- ğŸ“– **Documentation**: [READNE.md](https://github.com/yourusername/groxpi/README.md)

---

## ğŸ† **Why Choose groxpi?**

- **âš¡ 15.4x Faster**: Proven 43,335 req/sec vs 2,823 req/sec throughput
- **ğŸš€ 30x Better Latency**: 1.12ms vs 33.6ms P50 response times
- **ğŸ”¥ Sub-millisecond Performance**: Consistent P50 latency under load
- **ğŸš€ Production Ready**: Built with Go for enterprise reliability
- **ğŸ”„ Zero Migration**: Drop-in replacement for proxpi
- **â˜ï¸ Enterprise Features**: S3 storage, monitoring, compression

---

**groxpi** - *Making PyPI caching blazingly fast, incredibly efficient, and enterprise ready* ğŸš€